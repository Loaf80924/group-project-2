def make_session() -> requests.Session:
    s = requests.Session()
    hdrs = {
        "User-Agent": "AcademicResearchAssistant/1.0 (Python; CLI)",
    }
    if CROSSREF_MAILTO:
        hdrs["Mailto"] = CROSSREF_MAILTO  # Crossref polite usage
    s.headers.update(hdrs)

    retry = Retry(
        total=4,
        backoff_factor=0.6,
        status_forcelist=(429, 500, 502, 503, 504),
        allowed_methods=frozenset(["GET"]),
        raise_on_status=False,
    )
    adapter = HTTPAdapter(max_retries=retry)
    s.mount("https://", adapter)
    s.mount("http://", adapter)
    return s


# -----------------------------------------------------------------------------
# Helpers
# -----------------------------------------------------------------------------
def short_author(author_obj: dict) -> str:
    given = (author_obj.get("given") or "").strip()
    family = (author_obj.get("family") or "").strip()
    if not family and not given:
        return ""
    initial = (given[:1] + ".") if given else ""
    return f"{family}, {initial}".strip().strip(",")


def format_authors_apa(authors_list: List[dict]) -> str:
    names = [short_author(a) for a in authors_list if a]
    names = [n for n in names if n]
    if not names:
        return ""
    if len(names) == 1:
        return names[0]
    if len(names) <= 20:
        return ", ".join(names[:-1]) + ", & " + names[-1]
    # APA 7: first 19, ellipsis, last
    first_19 = ", ".join(names[:19])
    return f"{first_19}, â€¦, {names[-1]}"


def extract_year(item: dict) -> Optional[str]:
    for key in ("published-print", "published-online", "issued"):
        dp = item.get(key, {}).get("date-parts")
        if dp and isinstance(dp, list) and dp[0]:
            try:
                return str(dp[0][0])
            except Exception:  # pragma: no cover
                continue
    return None


def strip_tags(text: str) -> str:
    # Crossref abstracts can be JATS/XML or HTML-ish; remove tags & entities
    text = re.sub(r"<[^>]+>", " ", text or "")
    text = re.sub(r"&[a-zA-Z]+;", " ", text)
    return re.sub(r"\s+", " ", text).strip()


def apa_citation(title: str, authors_meta: List[dict], year: Optional[str], doi: str) -> str:
    authors = format_authors_apa(authors_meta or [])
    year_part = f"({year})" if year else "(n.d.)"
    doi_part = f"https://doi.org/{doi}" if doi else ""
    pieces = [p for p in [authors, year_part, f"{title}.", doi_part] if p]
    return " ".join(pieces).strip()


def fallback_extractive_summary(text: str, max_sentences: int = 3) -> str:
    sents = [s.strip() for s in text.replace("\n", " ").split(".") if s.strip()]
    return ". ".join(sents[:max_sentences]) + ("." if sents else "")


def summarize_with_openai(prompt: str) -> Optional[str]:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return None
    try:
        import openai  # type: ignore

        openai.api_key = api_key
        try:
            resp = openai.ChatCompletion.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=200,
            )
        except Exception:
            resp = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=200,
            )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        logging.debug("OpenAI summarize error: %s", e)
        return None


def build_summary(title: str, authors_text: str, doi: str, abstract_text: Optional[str] = None) -> str:
    base = strip_tags(abstract_text or "") if abstract_text else ""
    if not base:
        base = f"Paper titled '{title}' by {authors_text}. DOI: {doi or 'N/A'}."
    prompt = (
        "Summarize the academic paper below in 3 sentences covering key findings, "
        "methodology, and conclusion. Keep it objective and specific.\n\n"
        f"{base}"
    )
    ai_sum = summarize_with_openai(prompt)
    return ai_sum or fallback_extractive_summary(base, max_sentences=3)


# -----------------------------------------------------------------------------
# Crossref search
# -----------------------------------------------------------------------------
def search_crossref(query: str, max_results: int = 5, session: Optional[requests.Session] = None) -> List[Article]:
    session = session or make_session()
    params = {"query.title": query, "rows": max_results}
    logging.info("Crossref query: %s", params)
    res = session.get(CROSSREF_API, params=params, timeout=20)
    res.raise_for_status()
    items = res.json().get("message", {}).get("items", []) or []
    results: List[Article] = []
    for it in items:
        title = (it.get("title") or [""])[0] or "Untitled"
        authors_meta = it.get("author") or []
        authors_text = ", ".join(
            [f"{a.get('given','')} {a.get('family','')}".strip() for a in authors_meta if a]
        )
        doi = it.get("DOI") or ""
        year = extract_year(it)
        abstract = it.get("abstract")
        results.append(
            Article(
                title=title,
                authors_text=authors_text or "Unknown authors",
                authors_meta=authors_meta,
                doi=doi,
                year=year,
                raw=it,
                summary=build_summary(title, authors_text, doi, abstract),
                citation=apa_citation(title, authors_meta, year, doi),
            )
        )
    return results


# -----------------------------------------------------------------------------
# Persistence
# -----------------------------------------------------------------------------
def save_results(query: str, enriched: List[Article], db_path: str = DB_NAME) -> int:
    with sqlite3.connect(db_path) as conn:
        c = conn.cursor()
        ts = time.time()
        c.execute("INSERT INTO queries (query, timestamp) VALUES (?, ?)", (query, ts))
        qid = c.lastrowid
        for art in enriched:
            c.execute(
                """
                INSERT INTO articles (query_id, title, authors, year, doi, summary, citation, raw)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (
                    qid,
                    art.title,
                    art.authors_text,
                    art.year,
                    art.doi,
                    art.summary,
                    art.citation,
                    json.dumps(art.raw or {}, ensure_ascii=False),
                ),
            )
        conn.commit()
        return qid


def fetch_last_query_results(limit: int = 10, db_path: str = DB_NAME) -> List[Dict]:
    with sqlite3.connect(db_path) as conn:
        c = conn.cursor()
        c.execute("SELECT id FROM queries ORDER BY timestamp DESC LIMIT 1")
        row = c.fetchone()
        if not row:
            return []
        qid = row[0]
        c.execute(
            """
            SELECT title, authors, year, doi, summary, citation
            FROM articles
            WHERE query_id = ?
            LIMIT ?
            """,
            (qid, limit),
        )
        rows = c.fetchall()
    results = []
    for r in rows:
        results.append(
            {"title": r[0], "authors": r[1], "year": r[2], "doi": r[3], "summary": r[4], "citation": r[5]}
        )
    return results


def export_last_results_csv(csv_path: str = "last_results.csv", db_path: str = DB_NAME) -> Optional[str]:
    rows = fetch_last_query_results(limit=100, db_path=db_path)
    if not rows:
        return None
    with open(csv_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=list(rows[0].keys()))
        writer.writeheader()
        writer.writerows(rows)
    return csv_path


# -----------------------------------------------------------------------------
# Document save
# -----------------------------------------------------------------------------
def save_project_document_md(path: str = PROJECT_DOC_MD) -> str:
    Path(path).write_text(PROJECT_DOCUMENT, encoding="utf-8")
    return path


# -----------------------------------------------------------------------------
# CLI
# -----------------------------------------------------------------------------
def print_article(idx: int, art: Dict | Article) -> None:
    if isinstance(art, Article):
        title = art.title
        authors = art.authors_text
        year = art.year or "n.d."
        doi = art.doi or "N/A"
        summary = art.summary
        citation = art.citation
    else:
        title = art.get("title", "Untitled")
        authors = art.get("authors") or "Unknown authors"
        year = art.get("year") or "n.d."
        doi = art.get("doi") or "N/A"
        summary = art.get("summary")
        citation = art.get("citation")

    header = f"[{idx}] {title}"
    print(header)
    print("-" * len(header))
    print(f"Authors: {authors}")
    print(f"Year:    {year}")
    print(f"DOI:     {doi}")
    if summary:
        print("\nSummary:")
        print(textwrap.fill(summary, width=TEXT_WRAP_WIDTH))
    if citation:
        print("\nAPA Citation:")
        print(textwrap.fill(citation, width=TEXT_WRAP_WIDTH))
    print()


def do_search_flow() -> None:
    query = input("\nEnter your research query: ").strip()
    if not query:
        print("No query entered.")
        return
    print("\nSearching Crossref...")
    try:
        session = make_session()
        hits = search_crossref(query, max_results=5, session=session)
        if not hits:
            print("No results found.")
            return
        qid = save_results(query, hits)
        print(f"\nSaved {len(hits)} articles under query id {qid}.\n")
        for i, art in enumerate(hits, 1):
            print_article(i, art)
    except requests.HTTPError as e:
        print(f"HTTP error during search: {e}")
    except Exception as e:
        print(f"Error during search: {e}")


def do_export_csv() -> None:
    path = export_last_results_csv()
    if path:
        print(f"Exported last results to {path}")
    else:
        print("No previous results to export.")


def do_show_last() -> None:
    rows = fetch_last_query_results()
    if not rows:
        print("No previous results.")
        return
    for i, r in enumerate(rows, 1):
        print_article(i, r)


def do_save_doc() -> None:
    path = save_project_document_md()
    print(f"Saved project document to {path}")


def main() -> None:
    print("Welcome to the AI Chatbot for Academic Research Assistance (CLI)")
    print("NOTE: Set OPENAI_API_KEY to enable AI summaries (optional).")
    if CROSSREF_MAILTO:
        print("Using CROSSREF_MAILTO for polite API usage.")
    init_db()
    try:
        while True:
            print("\nChoose an option:")
            print("  1) Search scholarly articles")
            print("  2) Show last results")
            print("  3) Export last results to CSV")
            print("  4) Save project document (Markdown)")
            print("  5) Quit")
            choice = input("> ").strip()
            if choice == "1":
                do_search_flow()
            elif choice == "2":
                do_show_last()
            elif choice == "3":
                do_export_csv()
            elif choice == "4":
                do_save_doc()
            elif choice in ("5", "q", "quit", "exit"):
                print("Goodbye!")
                break
            else:
                print("Invalid choice. Please select 1-5.")
    except (KeyboardInterrupt, EOFError):
        print("\nGoodbye!")
        sys.exit(0)


if __name__ == "__main__":
    main()
